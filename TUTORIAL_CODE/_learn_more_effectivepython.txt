Learn more about
--------------------------------------------
http://www.python.org/dev/peps/pep-0008/
https://www.pylint.org/
encode decode, binary, unicode, utf-8
random_bits |= 1 << i
closure - outer/inner, stateful
open(self.path).read()
key
classmethod
USE MULTIPLE INHERITANCE ONLY FOR MIX-IN UTILITY CLASSES
PREFER PUBLIC ATTRIBUTES OVER PRIVATE ONES
__call__
bolierplate
iterator and container
if iter(numbers) is iter(numbers)
iterator generator
popen, popen2, and os.exec, subprocess
asyncio - blocking io
http://ipython.org
http://sphinx-doc.org
https://readthedocs.org
http://www.python.org/dev/peps/pep-0257/
doctest
namespace packages - https://www.python.org/dev/peps/pep-0420/
http://nose.readthedocs.org/)
http://pytest.org/

PYTHONIC THINKING
******************

KNOW WHICH VERSION OF PYTHON YOU’RE USING
-----------------------------------------
# program 2

Python 2 is frozen beyond bug fixes, security improvements, and backports
Helpful tools like the 2to3 and six exist to make it easier to adopt Python 3 going forward

FOLLOW THE PEP 8 STYLE GUIDE
-----------------------------
Python Enhancement Proposal #8

Whitespace: In Python, whitespace is syntactically significant. Python programmers are especially sensitive to the effects of whitespace on code clarity.

• Use spaces instead of tabs for indentation.
• Use four spaces for each level of syntactically significant indenting.
• Lines should be 79 characters in length or less.
• Continuations of long expressions onto additional lines should be indented by four extra spaces from their normal indentation level.
• In a file, functions and classes should be separated by two blank lines.
• In a class, methods should be separated by one blank line.
• Don’t put spaces around list indexes, function calls, or keyword argument assignments.
• Put one—and only one—space before and after variable assignments.

Naming: PEP 8 suggests unique styles of naming for different parts in the language. This makes it easy to distinguish which type corresponds to each name when reading code.

• Functions, variables, and attributes should be in lowercase_underscore format.
• Protected instance attributes should be in _leading_underscore format.
• Private instance attributes should be in __double_leading_underscore format.
• Classes and exceptions should be in CapitalizedWord format.
• Module-level constants should be in ALL_CAPS format.
• Instance methods in classes should use self as the name of the first parameter (which refers to the object).
• Class methods should use cls as the name of the first parameter (which refers to the class).

Expressions and Statements: The Zen of Python states: “There should be one—and preferably only one—obvious way to do it.” PEP 8 attempts to codify this style in its guidance for expressions and statements.

• Use inline negation (if a is not b) instead of negation of positive expressions (if not a is b).
• Don’t check for empty values (like [] or '') by checking the length (if len(somelist) == 0). Use if not somelist and assume empty values implicitly evaluate to False.
• The same thing goes for non-empty values (like [1] or 'hi'). The statement if somelist is implicitly True for non-empty values.
• Avoid single-line if statements, for and while loops, and except compound statements. Spread these over multiple lines for clarity.
• Always put import statements at the top of a file.
• Always use absolute names for modules when importing them, not names relative to the current module’s own path. For example, to import the foo module from the bar package, you should do from bar import foo, not just import foo.
• If you must do relative imports, use the explicit syntax from . import foo.
• Imports should be in sections in the following order: standard library modules, third-party modules, your own modules. Each subsection should have imports in alphabetical order.

pylint abc.py

KNOW THE DIFFERENCES BETWEEN BYTES, STR, AND UNICODE
---------------------------------------------------------
In Python 3, there are two types that represent sequences of characters: bytes and str. Instances of bytes contain raw 8-bit values. Instances of str contain Unicode characters.

In Python 2, there are two types that represent sequences of characters: str and unicode. In contrast to Python 3, instances of str contain raw 8-bit values. Instances of unicode contain Unicode characters.

To convert Unicode characters to binary data, you must use the encode method. To convert binary data to Unicode characters, you must use the decode method.

it’s important to do encoding and decoding of Unicode at the furthest boundary of your interfaces. 
This approach allows you to be very accepting of alternative text encodings (such as Latin-1, Shift JIS, and Big5) while being strict about your output text encoding (ideally, UTF-8).

# program 3

The first issue is that in Python 2, unicode and str instances seem to be the same type when a str only contains 7-bit ASCII characters.

In Python 3, bytes and str instances are never equivalent—not even the empty string

The second issue is that in Python 3, operations involving file handles (returned by the open built-in function) default to UTF-8 encoding. In Python 2, file operations default to binary encoding.
you must indicate that the data is being opened in write binary mode ('wb') instead of write character mode ('w')
Indicate binary mode by using 'rb' instead of 'r' when opening a file

# program 4

WRITE HELPER FUNCTIONS INSTEAD OF COMPLEX EXPRESSIONS
-----------------------------------------------------
# program 5, 6, 7

and or --> if else --> helper funcs

KNOW HOW TO SLICE SEQUENCES
---------------------------
Slicing can be extended to any Python class that implements the __getitem__ and __setitem__ special methods

somelist[start:end]

When slicing from the start of a list, you should leave out the zero index to reduce visual noise.
When slicing to the end of a list, you should leave out the final index because it’s redundant.
Slicing deals properly with start and end indexes that are beyond the boundaries of the list. That makes it easy for your code to establish a maximum length to consider for an input sequence.

somelist[-0:] will result in a copy of the original list.
The result of slicing a list is a whole new list.
References to the objects from the original list are maintained.
Modifying the result of slicing won’t affect the original list.

When used in assignments, slices will replace the specified range in the original list. Unlike tuple assignments (like a, b = c[:2]), the length of slice assignments don’t need to be the same. The values before and after the assigned slice will be preserved. The list will grow or shrink to accommodate the new values.

# program 8

AVOID USING START, END, AND STRIDE IN A SINGLE SLICE
-----------------------------------------------------
somelist[start:end:stride]

# program 9

To prevent problems, avoid using stride along with start and end indexes. If you must use a stride, prefer making it a positive value and omit start and end indexes. If you must use stride with start or end indexes, consider using one assignment to stride and another to slice.
Slicing and then striding will create an extra shallow copy of the data.

# program 10

1 step - itertools built-in module’s islice method , which doesn’t permit negative values for start, end, or stride.

USE LIST COMPREHENSIONS INSTEAD OF MAP AND FILTER
-------------------------------------------------
Dictionaries and sets also support comprehension expressions.

# program 11, 12

AVOID MORE THAN TWO EXPRESSIONS IN LIST COMPREHENSIONS
------------------------------------------------------
# program 13, 14

List comprehensions also support multiple if conditions.
Multiple conditions at the same loop level are an implicit and expression.

Conditions can be specified at each level of looping after the for expression. 

# program 15

The rule of thumb is to avoid using more than two expressions in a list comprehension. This could be two conditions, two loops, or one condition and one loop.

As soon as it gets more complicated than that, you should use normal if and for statements and write a helper function

CONSIDER GENERATOR EXPRESSIONS FOR LARGE COMPREHENSIONS
------------------------------------------------------
# program 16, 17

The only gotcha is that the iterators returned by generator expressions are stateful, so you must be careful not to use them more than once
 
Generator expressions avoid memory issues by producing outputs one at a time as an iterator.
 
Generator expressions can be composed by passing the iterator from one generator expression into the for subexpression of another.
 
PREFER ENUMERATE OVER RANGE
------------------------------
enumerate wraps any iterator with a lazy generator. This generator yields pairs of the loop index and the next value from the iterator.

# program 18, 19

USE ZIP TO PROCESS ITERATORS IN PARALLEL
-----------------------------------------
# program 20

The zip generator yields tuples containing the next value from each iterator.

# program 21

Python 2 zip is not a generator but a list
hence, izip from the itertools built-in module

longer lists last part not used

hence,
zip_longest function from the itertools built-in module instead (also called izip_longest in Python 2)

AVOID ELSE BLOCKS AFTER FOR AND WHILE LOOPS
-------------------------------------------
# program 22, 23

TAKE ADVANTAGE OF EACH BLOCK IN TRY/EXCEPT/ELSE/FINALLY
---------------------------------------------------------
# program 24

FUNCTIONS
**********

PREFER EXCEPTIONS TO RETURNING NONE
-----------------------------------
# program 25, 26

KNOW HOW CLOSURES INTERACT WITH VARIABLE SCOPE
----------------------------------------------
# program 27

When you reference a variable in an expression, the Python interpreter will traverse the scope to resolve the reference in this order:

1. The current function’s scope

2. Any enclosing scopes (like other containing functions)

3. The scope of the module that contains the code (also called the global scope)

4. The built-in scope (that contains functions like len and str)

If none of these places have a defined variable with the referenced name, then a NameError exception is raised.

Assigning a value to a variable works differently.
If the variable is already defined in the current scope,
then it will just take on the new value. If the variable doesn’t exist in the current scope,
then Python treats the assignment as a variable definition.
The scope of the newly defined variable is the function that contains the assignment.

hence use nonlocal variable
nonlocal won’t traverse up to the module-level scope

# program 28

use in small functions only
better to use helper class for long

# program 29

Python 2 doesn’t support the nonlocal keyword, hence use alternative

# program 30

Closure functions can refer to variables from any of the scopes in which they were defined.

CONSIDER GENERATORS INSTEAD OF RETURNING LISTS
----------------------------------------------
# program 31

When called, generator functions do not actually run but instead immediately return an iterator. 

# program 32

BE DEFENSIVE WHEN ITERATING OVER ARGUMENTS
------------------------------------------
# program 33

One way around this is to accept a function that returns a new iterator each time it’s called.

# program 34

Though it works, having to pass a lambda function like this is clumsy.
The better way to achieve the same result is to provide a new container class that implements the iterator protocol.

# program 35

The only downside of this approach is that it reads the input data multiple times.

an iterator is passed to the iter built-in function, iter will return the iterator itself. In contrast, when a container type is passed to iter, a new iterator object will be returned each time.

# program 36

REDUCE VISUAL NOISE WITH VARIABLE POSITIONAL ARGUMENTS
------------------------------------------------------
# program 37

The first issue is that the variable arguments are always turned into a tuple before they are passed to your function.
This means that if the caller of your function uses the * operator on a generator,
it will be iterated until it’s exhausted.
The resulting tuple will include every value from the generator,
which could consume a lot of memory and cause your program to crash.
best for small
better - keyword-only arguments 

PROVIDE OPTIONAL BEHAVIOR WITH KEYWORD ARGUMENTS
-------------------------------------------------
# program 38
The best practice is to always specify optional arguments using the keyword names
and never pass them as positional arguments.

USE NONE AND DOCSTRINGS TO SPECIFY DYNAMIC DEFAULT ARGUMENTS
------------------------------------------------------------
# program 39

ENFORCE CLARITY WITH KEYWORD-ONLY ARGUMENTS
-------------------------------------------
# program 40

Classes and Inheritance
************************

PREFER HELPER CLASSES OVER BOOKKEEPING WITH DICTIONARIES AND TUPLES
--------------------------------------------------------------------
# program 42

As soon as you find yourself going longer than a two-tuple, it’s time to consider another approach
The namedtuple type in the collections module does exactly what you need. It lets you easily define tiny, immutable data classes.

You can’t specify default argument values for namedtuple classes. If you find yourself using more than a handful of attributes, defining your own class may be a better choice.

The attribute values of namedtuple instances are still accessible using
numerical indexes and iteration. Especially in externalized APIs,
this can lead to unintentional usage that makes it harder to move to a real class later.
If you’re not in control of all of the usage of your namedtuple instances,
it’s better to define your own class.

# program 43

ACCEPT FUNCTIONS FOR SIMPLE INTERFACES INSTEAD OF CLASSES
---------------------------------------------------------
# program 44

USE @CLASSMETHOD POLYMORPHISM TO CONSTRUCT OBJECTS GENERICALLY
--------------------------------------------------------------
# program 45

USE MULTIPLE INHERITANCE ONLY FOR MIX-IN UTILITY CLASSES
--------------------------------------------------------
A mix-in is a small class that only defines a set of additional
methods that a class should provide.
Mix-in classes don’t define their own instance attributes nor require their
__init__ constructor to be called.

# program 47

PREFER PUBLIC ATTRIBUTES OVER PRIVATE ONES
------------------------------------------
# program 48

INHERIT FROM COLLECTIONS.ABC FOR CUSTOM CONTAINER TYPES
-------------------------------------------------------
Every Python class is a container of some kind
lists, tuples, sets, and dictionaries also

# program 49

Metaclasses and Attributes
***************************

USE PLAIN ATTRIBUTES INSTEAD OF GET AND SET METHODS
---------------------------------------------------
# program 50

CONSIDER @PROPERTY INSTEAD OF REFACTORING ATTRIBUTES
----------------------------------------------------
# program 51

USE DESCRIPTORS FOR REUSABLE @PROPERTY METHODS
-----------------------------------------------
# program 52

USE __GETATTR__, __GETATTRIBUTE__, AND __SETATTR__ FOR LAZY ATTRIBUTES
-----------------------------------------------------------------------
# program 53

VALIDATE SUBCLASSES WITH METACLASSES
---------------------------------------
# program 54

REGISTER CLASS EXISTENCE WITH METACLASSES
-----------------------------------------
# program 55, 56

ANNOTATE CLASS ATTRIBUTES WITH METACLASSES
------------------------------------------
Metaclasses enable you to modify a class’s attributes before the class is fully defined.

Image Descriptors and metaclasses make a powerful combination for declarative behavior and runtime introspection.

Image You can avoid both memory leaks and the weakref module by using metaclasses along with descriptors.

# program 57

Concurrency and Parallelism
----------------------------
USE SUBPROCESS TO MANAGE CHILD PROCESSES
-----------------------------------------
concurrency - computer does diff things SEEMINGLY at the same time, by switching programs quickly in single core cpu
paralellism - actually doing so on multi core cpu
Within a single program, concurrency is a tool that makes it easier for programmers to solve certain types of problems. Concurrent programs enable many distinct paths of execution to make forward progress in a way that seems to be both simultaneous and independent.
paralellism provides speed
Python makes it easy to write concurrent programs. Python can also be used to do parallel work through system calls, subprocesses, and C-extensions. But it can be very difficult to make concurrent Python code truly run in parallel. It’s important to understand how to best utilize Python in these subtly different situations.
child processes can run in parallel
many ways to run subprocesses over the years, including popen, popen2, and os.exec*.
subprocess  best for now
# program 58, 59
Decoupling the child process from the parent means that the parent process is free to run many child processes in parallel. You can do this by starting all the child processes together upfront.
# program 60
You can also pipe data from your Python program into a subprocess and retrieve its output.
#program61,62,63,64

USE THREADS FOR BLOCKING I/O, AVOID FOR PARALLELISM
----------------------------------------------------
cpython complies and then runs
Although Python supports multiple threads of execution, the GIL causes only one of them to make forward progress at a time.
#program65
not efficient but used for:
seems parallel
also
Blocking I/O includes things like reading and writing files, interacting with networks, communicating with devices like displays, etc. Threads help you handle blocking I/O by insulating your program from the time it takes for the operating system to respond to your requests.
system calls can run in parallel with python program
although python program tasks cant run in parallel due to gil
gil is released for system calls
#66

USE LOCK TO PREVENT DATA RACES IN THREADS
------------------------------------------
Although only one Python thread runs at a time, a thread’s operations on data structures can be interrupted between any two bytecode instructions in the Python interpreter.This is dangerous if you access the same objects from multiple threads simultaneously.
67 68

USE QUEUE TO COORDINATE WORK BETWEEN THREADS
--------------------------------------------
69 to 73

CONSIDER COROUTINES TO RUN MANY FUNCTIONS CONCURRENTLY
----------------------------------------------------------
about 8 MB per executing thread
Coroutines let you have many seemingly simultaneous functions in your Python programs. They’re implemented as an extension to generators
The cost of starting a generator coroutine is a function call. Once active, they each use less than 1 KB of memory until they’re exhausted.
Coroutines work by enabling the code consuming a generator to send a value back into the generator function after each yield expression. The generator function receives the value passed to the send function as the result of the corresponding yield expression.
74 75 76

CONSIDER CONCURRENT.FUTURES FOR TRUE PARALLELISM
------------------------------------------------
The multiprocessing built-in module, easily accessed via the concurrent.futures built-in module, may be exactly what you need. It enables Python to utilize multiple CPU cores in parallel by running additional interpreters as child processes. These child processes are separate from the main interpreter, so their global interpreter locks are also separate.
Each child can fully utilize one CPU core. Each child has a link to the main process where it receives instructions to do computation and returns results.
77

DEFINE FUNCTION DECORATORS WITH FUNCTOOLS.WRAPS
-----------------------------------------------
Decorators have the ability to run additional code before and after any calls to the functions they wrap.
This functionality can be useful for enforcing semantics, debugging, registering functions, and more
For example, say you want to print the arguments and return value of a function call.
78

CONSIDER CONTEXTLIB AND WITH STATEMENTS FOR REUSABLE TRY/FINALLY BEHAVIOR
---------------------------------------------------------------------------
The with statement in Python is used to indicate when code is running in a special context.
79

MAKE PICKLE RELIABLE WITH COPYREG
----------------------------------
80
The pickle built-in module can serialize Python objects into a stream of bytes and deserialize bytes back into objects.
Pickled byte streams shouldn’t be used to communicate between untrusted parties. The purpose of pickle is to let you pass Python objects between programs that you control over binary channels.
In contrast, the json module is safe by design.
81 - when user quits game, state can be saved to file

USE DATETIME INSTEAD OF TIME FOR LOCAL CLOCKS
---------------------------------------------
82

USE BUILT-IN ALGORITHMS AND DATA STRUCTURES
--------------------------------------------
83
84

USE DECIMAL WHEN PRECISION IS PARAMOUNT
----------------------------------------
85
The Decimal class provides fixed point math of 28 decimal points by default. It can go even higher if required.
For representing rational numbers with no limit to precision, consider using the Fraction class from the fractions built-in module.

pip is installed by default in Python 3.4 and above; you must install it yourself for older versions.

WRITE DOCSTRINGS FOR EVERY FUNCTION, CLASS, AND MODULE
-------------------------------------------------------
print(repr(palindrome.__doc__))  # function doc string
help function
write about default args and yield and exception
exclude returns None
If your function is a coroutine (see Item 40: “Consider Coroutines to Run Many Functions Concurrently”), then your docstring should contain what the coroutine yields, what it expects to receive from yield expressions, and when it will stop iteration.

Use Packages to Organize Modules and Provide Stable APIs
---------------------------------------------------------
__init__.py
available for importing with relative path
namespace packages - from separate directories/zip archives/remote systems
packages provide namespaces - eg: same filename in diff packages
as clause to rename
or without as we can use completely import x.y, d.y - x.y.func(), d.y.func()
provides stable apis
when we do from foo import * , the foo.__all__ attributes get imported
if __all__ attribute does not exist then only public attributes without leading _s exist
multiple import *s are unsafe
so from x import y is better
86

Define a Root Exception to Insulate Callers from APIs
------------------------------------------------------
we can raise exceptions on purpose so that caller can catch them
prevents cascading of issues
when there is a real exception, its becauze of bad api exception handling then
we can subclass our own exceptions
87

Know How to Break Circular Dependencies
=======================================
when import is done
module is searched in locations of sys.path
loads and compiles that code
creates an empty module object
inserts the module in sys.module
runs the code in module objects
In the example above, the app module imports dialog before defining anything. Then, the dialog module imports app. Since app still hasn’t finished running—it’s currently importing dialog—the app module is just an empty shell (from step #4). The AttributeError is raised (during step #5 for dialog) because the code that defines prefs hasn’t run yet (step #5 for app isn’t complete).

The best solution to this problem is to refactor your code so that the prefs data structure is at the bottom of the dependency tree. Then, both app and dialog can import the same utility module and avoid any circular dependencies. But such a clear division isn’t always possible or could require too much refactoring to be worth the effort.
88

Use Virtual Environments for Isolated and Reproducible Dependencies
--------------------------------------------------------------------
89

Consider Module-Scoped Code to Configure Deployment Environments
-----------------------------------------------------------------
90

Use repr Strings for Debugging Output
-------------------------------------
91

Test Everything with unittest
----------------------------
92

Consider Interactive Debugging with pdb
-------------------------------------------
93

Profile Before Optimizing
------------------------
94

Use tracemalloc to Understand Memory Usage and Leaks
----------------------------------------------------
95
